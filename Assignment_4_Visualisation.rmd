---
title: "Assignment 5 - Data Wrangling"
author: 'WST 212 2019'
date: "Due date 30 April 2019 before 13h00"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

Group Number: 

Group members: (Alphabetically)

1.)  Modise KM

2.) Rakgalakane TTT

3.) Tsoku K

4.)


--------------------------------------------------------------------------------------------------------------

Instructions:

.	Not more than four students in a group.

.	All students in a group will be allocated the same mark.

.	Only submit one assignment per group.

.	Only one submission per assignment will be allowed. Hence, only submit once all group members have agreed.

.	Use template below to answer all questions. Make sure that your questions are numbered correctly and that your answers correspond to the correct questions. If your answer is numbered incorrectly no marks will be awarded.

.	Please submit your assignment as a HTML file. This is done by knitting the RMarkdown file.

----------------------------------------------------------------------------------------------------------------
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Packages to use, message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
library(readr)
library(lubridate)
library(tidyr)

```

Reading Data
```{r}

coasters <- read.delim("coasters.txt", dec = ".", sep = "\t", header = TRUE)
burger <- read.delim("burger-king-items.txt", sep = "\t", dec = ".", header = TRUE)


```



#Question 1
Answer the questions for this assignment in the R practical markdown template and knit it to PDF.

a) Using the 'any(is.na)' function find out if there are any 'NA' values in the Burger King dataset.
```{r}
if(any(is.na(burger))) {
  print("TRUE")
} else {
  print("FALSE")
}


```


b) Find the data types of all the variables in the dataset. Also provide a summary of the dataset.

```{r}

sapply(burger, typeof)

```

```{r}
summary(burger)
```

c) Comment on which variables in the dataset could be catagorical variables. (Hint: These variables will only have a limited range of possible values such as '0','1' or '2'.) Convert these variables into factors to be used for modelling.

Variables Meat, Breakfast and Not.Breakfast can be converted into categorical variables since the value of these variables from the dataset are binary, "1" for yes and "0" for no, hence they have a limited range. 

```{r}

burger$Meat <- factor(burger$Meat)
burger$Breakfast <- factor(burger$Breakfast)
burger$Not.Breakfast <- factor(burger$Not.Breakfast)

```


d) Are there any redundant variable(s) in the dataset? If so, specify the variable(s) and remove the redundant variable(s). Also explain which variable(s) contains the same information and how to interpret the information.

Yes, the Breakfast and Not.Breakfast variables are redundant since "0" for one variable implies a "1" in the other variable.They give the same information and are thus redundant.

```{r}
burger <- subset(burger, select = -c(Not.Breakfast))

```


e) Draw a boxplot of the calories of the different Burger King items. Can you identify any items which have significantly more calories than the others?
```{r}


boxplot(burger$Calories)

```

#Question 2


```{r}

summary(is.na(coasters))

```

From the summary we can see that there is a total of 207 missing values. 123 of these values come from the "Drop" variable white the remaining 84 come from the "Duration" variable. None of the other variables have missing values.

```{r}
sapply(coasters, typeof)

```

From the output above we can see that the dataset have total of nine variables, five of which are of type integer and four of which are of type double.

**Frequency of values for the "Track Variable"**
```{r}
table(coasters$Track)
```

**Frequency of values for the "Inversions" variable**
```{r}
table(coasters$Inversions)
```

From the output above we can see that the "Track" and "Inversions" variables from the coasters dataset can only take on two possible values each. Since they have a limited range of values, we can consider them to be categorical variables and convert them into factors.

```{r}
coasters$Track <- factor(coasters$Track)
coasters$Inversions <- factor(coasters$Inversions)
```

#Question 3
Consider the 'Heart_data.csv' file provided on ClickUp. Provide a histogram of the age distribution as well as a frequency plot of the gender class.

``` {r}

heart <- read.delim("Heart_data.csv", sep = ",", dec = ".", header = TRUE)


heart <- separate(data = heart, gender.age, into = c("gender", "age"), sep = " ")
heart$age <- as.numeric(heart$age)
heart$gender <- factor(heart$gender)

hist(heart$age, main = "Histogram of Age", xlab = "Age")

barplot(table(heart$gender), main = "Frequency plot of Gender", xlab = "Gender")

```

#Question 4
Consider the 'Heart_data.csv' file provided on ClickUp. Provide a frequency plot of the *chd* variable. The *chd* variable is a binary indicator variable whose value should be either 1 for coronary heart disease present and 0 otherwise. Unfortunately the previous statistician captured a few *chd* response values incorrectly and has tasked you to correct this mistake. Ensure that you provide your methodolody as well as reasoning for your corrective measure. Provide the first 6 rows of the corrected variable. [Hint: Consider the "ifelse" function.]

```{r}

correct_values = 0
for(index in 1:length(heart$chd)) {
  
  ifelse( heart$chd[index] == 1 || heart$chd[index] == 0, correct_values <- correct_values + 1, heart$chd[index] <- heart$chd[index] ) 

}

correct_values / length(heart$chd)

```


#Question 5
An important process in data cleaning is handling missing values. Discuss **one** advantage and **one** disadvantage of each of the following techniques used to handle missing data. Make sure to mention the impact of the size of the data set and the type of the missing data (continuous or disctrete) where applicable. 


* Deletion of entries (see Table 1 for example)
* Using the mean, median or mode in place of the missing value.
* Using simple linear regression (see WST 111 notes)  to predict missing values.
* Using K-nearest neighbours to predict missing values. 

